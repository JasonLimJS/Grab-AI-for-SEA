{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble of 2 kNN Models (Weights Tuning).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonLimJS/Grab-AI-for-SEA/blob/master/Ensemble_of_2_kNN_Models_(Weights_Tuning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZcOUrDZRL82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.externals import joblib\n",
        "import pickle\n",
        "\n",
        "\n",
        "drive.mount('drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpcbSBWSRpwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw= pd.read_csv('drive/My Drive/raw.csv',index_col=0) #this file is created and saved in Model Development Doc.ipynb\n",
        "all_lag_1d= pd.read_csv('drive/My Drive/all_lag_1d.csv',index_col=0) #this file is created and saved in Model Development Doc.ipynb\n",
        "\n",
        "X= all_lag_1d.drop(['geohash6','day','demand'],axis=1)\n",
        "arranged_col= ['lat','long','time_min','demand_lag_1']\n",
        "X= X[arranged_col].values\n",
        "y= all_lag_1d.demand.values\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state= 7, \\\n",
        "                                                   test_size=0.2,stratify=X[:,2])\n",
        "\n",
        "X_test_1= X_test[:,:-1]\n",
        "\n",
        "mean_vect= np.array([ -5.34803514,  90.76456439, 611.01511076])\n",
        "sd_vect= np.array([5.74593198e-02, 1.02564882e-01, 3.91570353e+02])\n",
        "\n",
        "X_test_scaled1= (X_test_1- mean_vect)/sd_vect\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocu-uFq0Uvbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_mean= np.array([-5.34740478e+00,9.07638854e+01,6.10487686e+02,1.05574095e-01])\n",
        "norm_std= np.array([5.65621040e-02,1.02704766e-01,3.92263089e+02,1.59564436e-01])\n",
        "\n",
        "pca_mean= np.array([ 6.14163081e-15 ,1.66324146e-14 ,2.60231469e-16,-2.49625107e-14])\n",
        "pca_comp= np.array([[ 0.64256504 ,0.72425171, -0.21969293, -0.11960199],\n",
        "                    [-0.21087891,  0.07957761, -0.71483013,  0.66197838],\n",
        "                    [ 0.51445685, -0.2009283,   0.46599514,  0.69123838]])\n",
        "\n",
        "td0= (X_test- norm_mean)/norm_std\n",
        "td1 = td0 - pca_mean\n",
        "X_test_scaled2 = td1.dot(pca_comp.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U29pMUAnUvQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1= joblib.load('drive/My Drive/kNN_Model1.pkl')\n",
        "model2= joblib.load('drive/My Drive/whole_lag_1d_kNN.pkl')\n",
        "weight_vect= np.array(range(0,110,10))*0.01\n",
        "\n",
        "for weight in weight_vect:\n",
        "  weight_1= weight\n",
        "  weight_2= 1 - weight_1\n",
        "  \n",
        "  X= all_lag_1d.drop(['geohash6','day','demand'],axis=1)\n",
        "  arranged_col= ['lat','long','time_min','demand_lag_1']\n",
        "  X= X[arranged_col].values\n",
        "  y= all_lag_1d.demand.values\n",
        "  X_train, X_test, y_train, y_test= train_test_split(X, y, random_state= 7, \\\n",
        "                                                   test_size=0.2,stratify=X[:,2])\n",
        "  X_test_1= X_test[:,:-1]\n",
        "\n",
        "  mean_vect= np.array([ -5.34803514,  90.76456439, 611.01511076])\n",
        "  sd_vect= np.array([5.74593198e-02, 1.02564882e-01, 3.91570353e+02])\n",
        "\n",
        "  X_test_scaled1= (X_test_1- mean_vect)/sd_vect\n",
        "  \n",
        "  norm_mean= np.array([-5.34740478e+00,9.07638854e+01,6.10487686e+02,1.05574095e-01])\n",
        "  norm_std= np.array([5.65621040e-02,1.02704766e-01,3.92263089e+02,1.59564436e-01])\n",
        "  pca_mean= np.array([ 6.14163081e-15 ,1.66324146e-14 ,2.60231469e-16,-2.49625107e-14])\n",
        "  pca_comp= np.array([[ 0.64256504 ,0.72425171, -0.21969293, -0.11960199],\n",
        "                    [-0.21087891,  0.07957761, -0.71483013,  0.66197838],\n",
        "                    [ 0.51445685, -0.2009283,   0.46599514,  0.69123838]])\n",
        "\n",
        "  td0= (X_test- norm_mean)/norm_std\n",
        "  td1 = td0 - pca_mean\n",
        "  X_test_scaled2 = td1.dot(pca_comp.T)\n",
        "\n",
        "  y_pred1= model1.predict(X_test_scaled1)\n",
        "  y_pred2= model2.predict(X_test_scaled2)\n",
        "  y_pred_final= weight_1*y_pred1 + weight_2*y_pred2\n",
        "\n",
        "  rmse= MSE(y_test,y_pred_final)**0.5\n",
        "\n",
        "  print('weight_1: ' + str(weight_1) + ' ,weight_2: ' + str(weight_2) + ', rmse: ' + str(rmse))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQpBAIrX4oHD",
        "colab_type": "text"
      },
      "source": [
        "Tuning result:\n",
        "\n",
        "weight_1: 0.0 ,    weight_2: 1.0,    rmse: 0.06726763281100871\n",
        "\n",
        "weight_1: 0.1 ,    weight_2: 0.9,    rmse: 0.06446941562116118\n",
        "\n",
        "weight_1: 0.2 ,    weight_2: 0.8,    rmse: 0.062109990665184585\n",
        "\n",
        "weight_1: 0.3 ,    weight_2: 0.7,    rmse: 0.06024093785527065\n",
        "\n",
        "weight_1: 0.4 ,    weight_2: 0.6,    rmse: 0.05890895102014478\n",
        "\n",
        "weight_1: 0.5 ,    weight_2: 0.5,    rmse: 0.05815094745799957\n",
        "\n",
        "weight_1: 0.6 ,    weight_2: 0.4,    rmse: 0.05798943984545983\n",
        "\n",
        "weight_1: 0.7     ,weight_2: 0.3     rmse: 0.05842937480647346\n",
        "\n",
        "weight_1: 0.8 ,    weight_2: 0.2,    rmse: 0.059457403326402314\n",
        "\n",
        "weight_1: 0.9 ,    weight_2: 0.1,    rmse: 0.06104382068415746\n",
        "\n",
        "weight_1: 1.0 ,    weight_2: 0.0,    rmse: 0.06314655604606347\n",
        "\n",
        "Optimum weights:\n",
        "\n",
        "Model 1 (weight_1): 0.6\n",
        "\n",
        "Model 2(weight_2): 0.4"
      ]
    }
  ]
}